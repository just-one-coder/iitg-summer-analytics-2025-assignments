{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12139343,"sourceType":"datasetVersion","datasetId":7645102}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import cross_val_score\n\n# Load training and test data from CSV files\ntrain_df = pd.read_csv('/kaggle/input/hackathon-ndvi/hacktrain.csv')\ntest_df = pd.read_csv('/kaggle/input/hackathon-ndvi/hacktest.csv')\n\n# Drop any unnamed index columns if present\nfor col in ['Unnamed: 0']:\n    if col in train_df.columns:\n        train_df.drop(columns=[col], inplace=True)\n    if col in test_df.columns:\n        test_df.drop(columns=[col], inplace=True)\n\n# Identify NDVI columns (those ending with '_N') and sort them by date\nndvi_cols = sorted([c for c in train_df.columns if c.endswith('_N')])\n\n# Interpolate missing NDVI values row-wise for the training set\ntrain_ndvi = train_df[ndvi_cols].astype(float)\ntrain_ndvi_interp = train_ndvi.interpolate(axis=1, limit_direction='both')\n# If any values remain missing after interpolation, fill them with column medians\ntrain_ndvi_interp = train_ndvi_interp.fillna(train_ndvi.median(axis=0))\n\n# Interpolate missing NDVI values row-wise for the test set (should be no missing, but for safety)\ntest_ndvi = test_df[ndvi_cols].astype(float)\ntest_ndvi_interp = test_ndvi.interpolate(axis=1, limit_direction='both')\ntest_ndvi_interp = test_ndvi_interp.fillna(test_ndvi.median(axis=0))\n\n# Function to extract features from NDVI time series\ndef extract_features(df_ndvi):\n    features = pd.DataFrame(index=df_ndvi.index)\n    # Basic statistics for each time-series row\n    features['ndvi_mean']   = df_ndvi.mean(axis=1)\n    features['ndvi_std']    = df_ndvi.std(axis=1)\n    features['ndvi_min']    = df_ndvi.min(axis=1)\n    features['ndvi_max']    = df_ndvi.max(axis=1)\n    features['ndvi_range']  = features['ndvi_max'] - features['ndvi_min']\n    features['ndvi_median'] = df_ndvi.median(axis=1)\n    # First (earliest) and last (latest) NDVI values in the series\n    features['ndvi_first']  = df_ndvi.iloc[:, 0]\n    features['ndvi_last']   = df_ndvi.iloc[:, -1]\n    # Compute trend (slope) of NDVI over time for each row using least squares\n    x = np.arange(df_ndvi.shape[1])\n    x_mean = x.mean()\n    x_var = np.sum((x - x_mean)**2)\n    slopes = []\n    for _, row in df_ndvi.iterrows():\n        y = row.values\n        mask = ~np.isnan(y)\n        # If too few points, set slope to 0\n        if np.sum(mask) <= 1:\n            slopes.append(0.0)\n        else:\n            y_masked = y[mask]\n            x_masked = x[mask]\n            y_mean = y_masked.mean()\n            # slope = Cov(x,y) / Var(x)\n            slope = np.sum((x_masked - x_mean) * (y_masked - y_mean)) / x_var\n            slopes.append(slope)\n    features['ndvi_slope'] = slopes\n    return features\n\n# Extract features for training and test sets\ntrain_features = extract_features(train_ndvi_interp)\ntest_features  = extract_features(test_ndvi_interp)\n\n# Prepare training labels\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(train_df['class'])\n\n# Standardize features for logistic regression\nscaler = StandardScaler()\nX_train = scaler.fit_transform(train_features)\nX_test  = scaler.transform(test_features)\n\n# Initialize Logistic Regression with multiclass setting and balanced class weights\nclf = LogisticRegression(multi_class='multinomial', solver='lbfgs', \n                         class_weight='balanced', max_iter=1000, C=1.0)\n\n# Optional: check cross-validated accuracy (e.g., 5-fold)\n# cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n# print(f\"CV Accuracy: {cv_scores.mean():.3f}\")\n\n# Train on all training data\nclf.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = clf.predict(X_test)\npred_labels = label_encoder.inverse_transform(y_pred)\n\n# Prepare the submission DataFrame\nsubmission = pd.DataFrame({\n    'ID': test_df['ID'],\n    'class': pred_labels\n})\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-16T12:28:47.098129Z","iopub.execute_input":"2025-06-16T12:28:47.098495Z","iopub.status.idle":"2025-06-16T12:28:51.176034Z","shell.execute_reply.started":"2025-06-16T12:28:47.098459Z","shell.execute_reply":"2025-06-16T12:28:51.175204Z"}},"outputs":[],"execution_count":1}]}